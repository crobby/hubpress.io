<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Making sense of it]]></title><description><![CDATA[I'll talk about all sorts of things related to container-related computing]]></description><link>https://crobby.github.io/hubpress.io</link><generator>RSS for Node</generator><lastBuildDate>Mon, 30 Jan 2017 21:31:11 GMT</lastBuildDate><atom:link href="https://crobby.github.io/hubpress.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Yes, containerize it!]]></title><description><![CDATA[<div class="sect1">
<h2 id="_where_am_i_going_with_this">Where am I going with this?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This is meant to be a bit of an introductory post where I can explain a bit of where I&#8217;m coming from and where I think I&#8217;m headed.  Later posts will include tutorials and quickstart guides for using some of the work that I&#8217;m involved with that centers around running Apache Spark clusters on top of OpenShift.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_wow_containers_are_great">Wow, containers are great</h2>
<div class="sectionbody">
<div class="paragraph">
<p>I&#8217;m going to assume that this isn&#8217;t your first rodeo and that you know a bit about what containers are and how they work.  When I first stumbled on containers (via docker) a few years ago, I felt like I was watching a magic show.  I had done quite a bit of work with virtual machines and I was actively working on OpenStack.  Given that, my usual workflow to make something happen was 1) build an image (usually via something sort of painful like disk-image-builder), load it into my OpenStack instance, spin-up the vm and hope that it was working properly.  If not, rinse and repeat.  Each loop would take several minutes if I was lucky.  To see a container on my Fedora machine fire-up and run it CentOs bits at light speed was quite a rush.  A quick pull of the centrally-shared image and I was on my way.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_probably_not_just_for_hello_world_but_i_just_don_t_see_it_yet">Probably not just for "Hello, world!", but I just don&#8217;t see it yet</h2>
<div class="sectionbody">
<div class="paragraph">
<p>My first brush with containers was moslty just toying around.  Various flavors of "Hello, world!" were run and I was happy with that for the time being.  Surely, my mighty vms were still more interesting.  Making the vms networking and storage options work didn&#8217;t require a pile of command line args and there was already a lot of nice tooling around them.  The vms were still much more comforatble to me.  Making my containers do networking and storage seemed rather flimsy by comparisson.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_fast_forward_a_few_years_and_enter_kubernetes_and_openshift">Fast forward a few years and enter Kubernetes and OpenShift</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Eventually, I got around to taking a look at OpenShift, which is a customized spin of Kubernetes with some niceities around it (API tweaks, security, et al.).  After a quick one-liner to start up a single-node OpenShift instance (Do download an OpenShift release (<a href="https://github.com/openshift/origin/releases" class="bare">https://github.com/openshift/origin/releases</a>) and try the "oc cluster up" commandand---genius stuff) a few clicks, I had a small  containerized nodejs front end that interacted nicely with a containerized mongodb backend that "just worked".  On top of that it was scaleable with another click.  All that functionality running on my laptop in minutes with almost no knowledge or effort on my part.  No longer did the world of containers seem flimsy to me.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_doing_real_work_in_containers">Doing real work in containers?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Containers are lovely, but they are still only as useful as the software running in them.  Enter Apache Spark (<a href="http://spark.apache.org/" class="bare">http://spark.apache.org/</a>).  Spark is a great tool for processing super large scale datasets.  It has a basic master/worker architecture and in the past I had worked on bringing Spark to OpenStack&#8217;s Sahara project.  Sahara would spin-up a given number of vm instances to run a Spark master and some number of workers.  Terrific stuff really.  It worked great and still works today.  It does however, have the usual overhead of requiring N vms for an N node cluster (1 master and N-1 workers).  Maybe we can improve on that.  You guessed it&#8230;&#8203;.containerize it!</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_but_does_it_work">But does it work?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>It turns out that it&#8217;s not too hard to make the Spark processes run in a container.  OpenShift provides an object called a Deployment Configuration (<a href="https://docs.openshift.com/container-platform/latest/dev_guide/deployments/how_deployments_work.html" class="bare">https://docs.openshift.com/container-platform/latest/dev_guide/deployments/how_deployments_work.html</a>) that let you quickly define the parts of your Spark cluster (define which image to use, how many containers to spawn, etc).  You can even attach storage or access other services (databases?) in a very straightforward way.  Once your cluster is up scaling your cluster up or down to get the desired number of workers is done near instantly by a quick call to the replication controller for the deployment.  Given the ease of setting up a single node cluster along with some of the images and templates hosted in the radanalyticsio github (<a href="https://github.com/radanalyticsio" class="bare">https://github.com/radanalyticsio</a>) you can set up your own small Spark cluster and run your first job in well under 10 minuntes.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_not_a_perfect_world_yet">Not a perfect world&#8230;&#8203;yet</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Running multiple deployments to form a Spark cluster works well from some viewpoints, but a user might want to think of their cluster as a whole rather than the sum of a bunch of deployments that are glued together with some fancy networking.  That&#8217;s one place where OpenShift does not yet have an abstraction in place.  One of the projects that I work on has, among other things, the ability to see a cluster as a whole as one of the goals.  Via the templates and apps in <a href="https://github.com/radanalyticsio" class="bare">https://github.com/radanalyticsio</a> you can configure, start, and view a Spark cluster as an entity.  More to come on that in later blog posts.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__well_under_10_minutes_eh">"Well under 10 minutes", eh?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In my next post, I&#8217;ll take myself to task for making such a bold statement and race the clock to make the "Spark fly".</p>
</div>
</div>
</div>]]></description><link>https://crobby.github.io/hubpress.io/2017/01/30/Yes-containerize-it.html</link><guid isPermaLink="true">https://crobby.github.io/hubpress.io/2017/01/30/Yes-containerize-it.html</guid><category><![CDATA[openshift]]></category><category><![CDATA[ containers]]></category><category><![CDATA[ spark]]></category><category><![CDATA[ cluster]]></category><category><![CDATA[ big data]]></category><category><![CDATA[ extension]]></category><category><![CDATA[ angular]]></category><category><![CDATA[ origin]]></category><category><![CDATA[ kubernetes]]></category><category><![CDATA[ console]]></category><category><![CDATA[ docker]]></category><dc:creator><![CDATA[Chad Roberts]]></dc:creator><pubDate>Mon, 30 Jan 2017 00:00:00 GMT</pubDate></item></channel></rss>